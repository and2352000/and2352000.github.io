<!doctype html><html lang=en-us><head><title>Google Cloud Summit Review | Aaron's Blog</title>
<meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="
  

這次的 Google Cloud Summit 可以用 AI 來總結 🔗副標題可以叫做 RAG(Retrieval-Augmented Generation) 🔗這次的議程我參加了兩個 Workshop

Migration from PostgreSQL to Alloy DB for accelerating
GenAl Vector Search & Embedding
Multimodality with Gemini

有趣的案例 🔗語音客製化

Vertex AI 能夠進行類似人類的對話和互動，使得與客戶的交流更加自然，根據不同的語調性別年齡產生不同的語音還回應。

  


輿情分析 Tag 系統

輿情分析的時候需要大量的人原來對留言進行標注，這時候LLM 就很適合代替標注的人員

LLM 的誤解 🔗大多數人已經對 LLM 有所涉獵，但對其局限性認識不足。LLM 雖然功能強大，但在相似度搜索方面還不夠精確，而且有時候會唬爛。因此，需要使用 RAG 來提高搜索的精確性， 通常來講你必須給他一個比較既定事實陳述
Embedding 的基本概念 🔗簡單來說，Embedding 就是將一個對象轉換成向量，對象可以是任何數據（如語音、影片、文字）。然後透過向量搜索引擎找到與之最近的對象（即相似度最高的對象）。距離的算法有很多種，適用的場景也各不相同，有些適合全文搜索，有些則適合其他用途。
在 Embedding 領域，各家技術都有其優勢。

OpenAI 提供的嵌入向量有 3,072 維，而
Google 提供的嵌入向量則有 1,000 多維。Google 利用了其搜尋引擎的算法來生成這些嵌入向量。

不過市面上有很多開源的 embedding model ，距離的算法也很多，用的場景也不一樣
即時更新最新的資料 🔗
假設你是一個電商 你就可以透過 Embedding 在不把資料庫暴露的情況 update 最新資料, 你這時候就會有疑問 fine-tune 呢？？ 主要是貴 fine-tune 適用在模型更新不頻繁的時候

Fine-tune 🔗Fine-tune 是在模型更新不頻繁時的最佳選擇，雖然成本較高，但能針對特定需求進行調整。Fine-tune 可以看作是對 LLM 的進一步教育，讓它在既有的基礎上更好地適應特定任務。"><meta name=generator content="Hugo 0.145.0"><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/images/favicon.ico type=image/x-icon><script async src="https://www.googletagmanager.com/gtag/js?id=G-0YBZ467R0Y"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-0YBZ467R0Y")}</script></head><body><nav class=navigation><a href=/><span class=arrow>←</span>Home</a>
<a href=/posts>Archive</a>
<a href=/tags>Tags</a>
<a href=/about>About</a></nav><main class=main><section id=single><h1 class=title>Google Cloud Summit Review</h1><div class=tip><time datetime="2024-06-17 14:09:20 +0800 +0800">Jun 17, 2024</time>
<span class=split>·
</span><span>353 words
</span><span class=split>·
</span><span>2 minute read</span></div><div class=content><p><p class=markdown-image><img src=images/begin.JPG alt=Begin></p></p><h1 id=這次的-google-cloud-summit-可以用-ai-來總結>這次的 Google Cloud Summit 可以用 AI 來總結 <a href=#%e9%80%99%e6%ac%a1%e7%9a%84-google-cloud-summit-%e5%8f%af%e4%bb%a5%e7%94%a8-ai-%e4%be%86%e7%b8%bd%e7%b5%90 class=anchor>🔗</a></h1><h2 id=副標題可以叫做-ragretrieval-augmented-generation>副標題可以叫做 RAG(Retrieval-Augmented Generation) <a href=#%e5%89%af%e6%a8%99%e9%a1%8c%e5%8f%af%e4%bb%a5%e5%8f%ab%e5%81%9a-ragretrieval-augmented-generation class=anchor>🔗</a></h2><p>這次的議程我參加了兩個 Workshop</p><ul><li>Migration from PostgreSQL to Alloy DB for accelerating
GenAl Vector Search & Embedding</li><li>Multimodality with Gemini</li></ul><h2 id=有趣的案例>有趣的案例 <a href=#%e6%9c%89%e8%b6%a3%e7%9a%84%e6%a1%88%e4%be%8b class=anchor>🔗</a></h2><p>語音客製化</p><ul><li>Vertex AI 能夠進行類似人類的對話和互動，使得與客戶的交流更加自然，根據不同的語調性別年齡產生不同的語音還回應。<p class=markdown-image><img src=images/voice_usecase.png alt=voice></p></li></ul><p>輿情分析 Tag 系統</p><ul><li>輿情分析的時候需要大量的人原來對留言進行標注，這時候LLM 就很適合代替標注的人員</li></ul><h2 id=llm-的誤解>LLM 的誤解 <a href=#llm-%e7%9a%84%e8%aa%a4%e8%a7%a3 class=anchor>🔗</a></h2><p>大多數人已經對 LLM 有所涉獵，但對其局限性認識不足。LLM 雖然功能強大，但在相似度搜索方面還不夠精確，而且有時候會唬爛。因此，需要使用 RAG 來提高搜索的精確性， 通常來講你必須給他一個比較既定事實陳述</p><h2 id=embedding-的基本概念>Embedding 的基本概念 <a href=#embedding-%e7%9a%84%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5 class=anchor>🔗</a></h2><p>簡單來說，Embedding 就是將一個對象轉換成向量，對象可以是任何數據（如語音、影片、文字）。然後透過向量搜索引擎找到與之最近的對象（即相似度最高的對象）。距離的算法有很多種，適用的場景也各不相同，有些適合全文搜索，有些則適合其他用途。</p><p>在 Embedding 領域，各家技術都有其優勢。</p><ul><li>OpenAI 提供的嵌入向量有 3,072 維，而</li><li>Google 提供的嵌入向量則有 1,000 多維。Google 利用了其搜尋引擎的算法來生成這些嵌入向量。</li></ul><p>不過市面上有很多開源的 embedding model ，距離的算法也很多，用的場景也不一樣</p><h3 id=即時更新最新的資料>即時更新最新的資料 <a href=#%e5%8d%b3%e6%99%82%e6%9b%b4%e6%96%b0%e6%9c%80%e6%96%b0%e7%9a%84%e8%b3%87%e6%96%99 class=anchor>🔗</a></h3><ul><li>假設你是一個電商 你就可以透過 Embedding 在不把資料庫暴露的情況 update 最新資料, 你這時候就會有疑問 fine-tune 呢？？ 主要是貴 fine-tune 適用在模型更新不頻繁的時候</li></ul><h2 id=fine-tune>Fine-tune <a href=#fine-tune class=anchor>🔗</a></h2><p>Fine-tune 是在模型更新不頻繁時的最佳選擇，雖然成本較高，但能針對特定需求進行調整。Fine-tune 可以看作是對 LLM 的進一步教育，讓它在既有的基礎上更好地適應特定任務。</p><h2 id=比喻>比喻 <a href=#%e6%af%94%e5%96%bb class=anchor>🔗</a></h2><p>LLM 就像是一個五歲的小孩，有了基本的邏輯和知識，
透過 Fine-tune 看你教育他強化他什麼，可以讓它在特定領域表現得更好。
但我們總不能沒事就重新生小孩
Embedding 就像是一本參考書或字典，給與小孩與現實資料接觸(grounding)</p><h2 id=example>Example <a href=#example class=anchor>🔗</a></h2><ul><li>舉一個例子：如果你的使用者很智障 不知道要怎麼搜尋東西可以請LLM幫他。
請問有什麼好吃的 -> LLM (餐廳, 美食, 中餐) -> embedding 轉換 -> vector engine -> 無老鍋 -> LLM (我建議你吃無老鍋&mldr;.)</li></ul><h2 id=這次-google-強推的-aolly-database>這次 Google 強推的 Aolly Database <a href=#%e9%80%99%e6%ac%a1-google-%e5%bc%b7%e6%8e%a8%e7%9a%84-aolly-database class=anchor>🔗</a></h2><p><p class=markdown-image><img src=images/alloy_usage.png alt=Aolly></p></p><h3 id=aolly-database>Aolly Database <a href=#aolly-database class=anchor>🔗</a></h3><ul><li>高效的向量搜索：Alloy Database 支持高效的向量搜索，這對於需要進行大量相似性計算的應用（如推薦系統和自然語言處理）非常有用。</li><li>內建的向量操作支持：使用 pgvector，可以在 Alloy Database 中直接執行向量操作，無需額外的數據處理步驟。</li><li>兼容 PostgreSQL：Alloy Database 兼容 PostgreSQL，這使得從 PostgreSQL 遷移過程變得相對簡單，並且能夠繼續使用熟悉的工具和生態系統。</li></ul><p>Aolly Database 計算 vector distance</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>quickstart_db<span style=color:#f92672>=</span>&gt; 
</span></span><span style=display:flex><span>SELECT
</span></span><span style=display:flex><span>        cp.product_name,
</span></span><span style=display:flex><span>        left<span style=color:#f92672>(</span>cp.product_description,80<span style=color:#f92672>)</span> as description,
</span></span><span style=display:flex><span>        cp.sale_price,
</span></span><span style=display:flex><span>        cs.zip_code,
</span></span><span style=display:flex><span>        <span style=color:#f92672>(</span>cp.embedding &lt;<span style=color:#f92672>=</span>&gt; embedding<span style=color:#f92672>(</span><span style=color:#e6db74>&#39;textembedding-gecko&#39;</span>,<span style=color:#e6db74>&#39;What kind of fruit trees grow well here?&#39;</span><span style=color:#f92672>)</span>::vector<span style=color:#f92672>)</span> as distance
</span></span><span style=display:flex><span>FROM
</span></span><span style=display:flex><span>        cymbal_products cp
</span></span><span style=display:flex><span>JOIN cymbal_inventory ci on
</span></span><span style=display:flex><span>        ci.uniq_id<span style=color:#f92672>=</span>cp.uniq_id
</span></span><span style=display:flex><span>JOIN cymbal_stores cs on
</span></span><span style=display:flex><span>        cs.store_id<span style=color:#f92672>=</span>ci.store_id
</span></span><span style=display:flex><span>        AND ci.inventory&gt;0
</span></span><span style=display:flex><span>        AND cs.store_id <span style=color:#f92672>=</span> <span style=color:#ae81ff>1583</span>
</span></span><span style=display:flex><span>ORDER BY
</span></span><span style=display:flex><span>        distance ASC
</span></span><span style=display:flex><span>LIMIT 10;
</span></span></code></pre></div><p><p class=markdown-image><img src=images/vector_distance_result.png alt="vector result"></p></p><p>搭配 LLM 一起用</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>WITH trees as <span style=color:#f92672>(</span>
</span></span><span style=display:flex><span>SELECT
</span></span><span style=display:flex><span>    cp.product_name,
</span></span><span style=display:flex><span>    cp.product_description as description,
</span></span><span style=display:flex><span>    cp.sale_price,
</span></span><span style=display:flex><span>    cs.zip_code,
</span></span><span style=display:flex><span>    cp.uniq_id as product_id
</span></span><span style=display:flex><span>FROM
</span></span><span style=display:flex><span>    cymbal_products cp
</span></span><span style=display:flex><span>JOIN cymbal_inventory ci on
</span></span><span style=display:flex><span>    ci.uniq_id<span style=color:#f92672>=</span>cp.uniq_id
</span></span><span style=display:flex><span>JOIN cymbal_stores cs on
</span></span><span style=display:flex><span>    cs.store_id<span style=color:#f92672>=</span>ci.store_id
</span></span><span style=display:flex><span>    AND ci.inventory&gt;0
</span></span><span style=display:flex><span>    AND cs.store_id <span style=color:#f92672>=</span> <span style=color:#ae81ff>1583</span>
</span></span><span style=display:flex><span>ORDER BY
</span></span><span style=display:flex><span>    <span style=color:#f92672>(</span>cp.embedding &lt;<span style=color:#f92672>=</span>&gt; embedding<span style=color:#f92672>(</span><span style=color:#e6db74>&#39;textembedding-gecko&#39;</span>,<span style=color:#e6db74>&#39;What kind of fruit trees grow well here?&#39;</span><span style=color:#f92672>)</span>::vector<span style=color:#f92672>)</span> ASC
</span></span><span style=display:flex><span>LIMIT 1<span style=color:#f92672>)</span>,
</span></span><span style=display:flex><span>prompt as <span style=color:#f92672>(</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>select</span>
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;You are a friendly advisor helping to find a product based on the customer&#39;&#39;s needs.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>Based on the client request we have loaded a list of products closely related to search.
</span></span></span><span style=display:flex><span><span style=color:#e6db74>The list in JSON format with list of values like {&#34;product_name&#34;:&#34;name&#34;,&#34;product_description&#34;:&#34;some description&#34;,&#34;sale_price&#34;:10}
</span></span></span><span style=display:flex><span><span style=color:#e6db74>Here is the list of products:&#39;</span> <span style=color:#f92672>||</span> json_agg<span style=color:#f92672>(</span>trees<span style=color:#f92672>)</span> <span style=color:#f92672>||</span> <span style=color:#e6db74>&#39;The customer asked &#34;What kind of fruit trees grow well here?&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>You should give information about the product, price and some supplemental information&#39;</span> as prompt
</span></span><span style=display:flex><span>from
</span></span><span style=display:flex><span>    trees<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>select</span>
</span></span><span style=display:flex><span>    ml_predict_row<span style=color:#f92672>(</span>
</span></span><span style=display:flex><span> FORMAT<span style=color:#f92672>(</span><span style=color:#e6db74>&#39;publishers/google/models/%s&#39;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;text-bison&#39;</span><span style=color:#f92672>)</span>,
</span></span><span style=display:flex><span>    json_build_object<span style=color:#f92672>(</span><span style=color:#e6db74>&#39;instances&#39;</span>,
</span></span><span style=display:flex><span>    json_build_object<span style=color:#f92672>(</span><span style=color:#e6db74>&#39;prompt&#39;</span>,
</span></span><span style=display:flex><span>    prompt<span style=color:#f92672>)</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#39;parameters&#39;</span>,
</span></span><span style=display:flex><span>    json_build_object<span style=color:#f92672>(</span><span style=color:#e6db74>&#39;maxOutputTokens&#39;</span>,
</span></span><span style=display:flex><span>    2048<span style=color:#f92672>))</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>)</span>-&gt;<span style=color:#e6db74>&#39;predictions&#39;</span>-&gt;0-&gt;<span style=color:#e6db74>&#39;content&#39;</span>
</span></span><span style=display:flex><span>from
</span></span><span style=display:flex><span>    prompt;
</span></span></code></pre></div><p>REF: <a href=https://docs.google.com/document/d/1mvST8zbHH7cOvEL0VQUARzyIiqdNyX_gPjfOU-8NIRs/edit target=_blank rel=noopener>Migration from PostgreSQL to Alloy DB for accelerating
GenAl Vector Search & Embedding 參考資料</a></p></div><div class=tags><a href=https://and2352000.github.io/tags/ai>AI</a>
<a href=https://and2352000.github.io/tags/google>Google</a>
<a href=https://and2352000.github.io/tags/llm>LLM</a>
<a href=https://and2352000.github.io/tags/aolly>Aolly</a>
<a href=https://and2352000.github.io/tags/embedding>Embedding</a></div></section></main><footer id=footer><div class=copyright>© Copyright
2025
<span class=split><svg fill="#bbb" width="15" height="15" id="heart-15" width="15" height="15" viewBox="0 0 15 15"><path d="M13.91 6.75c-1.17 2.25-4.3 5.31-6.07 6.94-.1903.1718-.4797.1718-.67.0C5.39 12.06 2.26 9 1.09 6.75-1.48 1.8 5-1.5 7.5 3.45 10-1.5 16.48 1.8 13.91 6.75z"/></svg></span></div><div class=powerby>Powered by <a href=http://www.gohugo.io/>Hugo</a> Theme By <a href=https://github.com/nodejh/hugo-theme-mini>nodejh</a></div></footer></body></html>