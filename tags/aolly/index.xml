<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Aolly on Aaron's Blog</title><link>https://and2352000.github.io/tags/aolly/</link><description>Recent content in Aolly on Aaron's Blog</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 17 Jun 2024 14:09:20 +0800</lastBuildDate><atom:link href="https://and2352000.github.io/tags/aolly/index.xml" rel="self" type="application/rss+xml"/><item><title>Google Cloud Summit Review</title><link>https://and2352000.github.io/posts/8-google-cloud-summit-review/</link><pubDate>Mon, 17 Jun 2024 14:09:20 +0800</pubDate><guid>https://and2352000.github.io/posts/8-google-cloud-summit-review/</guid><description>&lt;p>&lt;p class="markdown-image">
 &lt;img src="images/begin.JPG" alt="Begin" />
&lt;/p>&lt;/p>
&lt;h1 id="這次的-google-cloud-summit-可以用-ai-來總結">這次的 Google Cloud Summit 可以用 AI 來總結 &lt;a href="#%e9%80%99%e6%ac%a1%e7%9a%84-google-cloud-summit-%e5%8f%af%e4%bb%a5%e7%94%a8-ai-%e4%be%86%e7%b8%bd%e7%b5%90" class="anchor">🔗&lt;/a>&lt;/h1>&lt;h2 id="副標題可以叫做-ragretrieval-augmented-generation">副標題可以叫做 RAG(Retrieval-Augmented Generation) &lt;a href="#%e5%89%af%e6%a8%99%e9%a1%8c%e5%8f%af%e4%bb%a5%e5%8f%ab%e5%81%9a-ragretrieval-augmented-generation" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>這次的議程我參加了兩個 Workshop&lt;/p>
&lt;ul>
&lt;li>Migration from PostgreSQL to Alloy DB for accelerating
GenAl Vector Search &amp;amp; Embedding&lt;/li>
&lt;li>Multimodality with Gemini&lt;/li>
&lt;/ul>
&lt;h2 id="有趣的案例">有趣的案例 &lt;a href="#%e6%9c%89%e8%b6%a3%e7%9a%84%e6%a1%88%e4%be%8b" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>語音客製化&lt;/p>
&lt;ul>
&lt;li>Vertex AI 能夠進行類似人類的對話和互動，使得與客戶的交流更加自然，根據不同的語調性別年齡產生不同的語音還回應。
&lt;p class="markdown-image">
 &lt;img src="images/voice_usecase.png" alt="voice" />
&lt;/p>&lt;/li>
&lt;/ul>
&lt;p>輿情分析 Tag 系統&lt;/p>
&lt;ul>
&lt;li>輿情分析的時候需要大量的人原來對留言進行標注，這時候LLM 就很適合代替標注的人員&lt;/li>
&lt;/ul>
&lt;h2 id="llm-的誤解">LLM 的誤解 &lt;a href="#llm-%e7%9a%84%e8%aa%a4%e8%a7%a3" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>大多數人已經對 LLM 有所涉獵，但對其局限性認識不足。LLM 雖然功能強大，但在相似度搜索方面還不夠精確，而且有時候會唬爛。因此，需要使用 RAG 來提高搜索的精確性， 通常來講你必須給他一個比較既定事實陳述&lt;/p>
&lt;h2 id="embedding-的基本概念">Embedding 的基本概念 &lt;a href="#embedding-%e7%9a%84%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>簡單來說，Embedding 就是將一個對象轉換成向量，對象可以是任何數據（如語音、影片、文字）。然後透過向量搜索引擎找到與之最近的對象（即相似度最高的對象）。距離的算法有很多種，適用的場景也各不相同，有些適合全文搜索，有些則適合其他用途。&lt;/p>
&lt;p>在 Embedding 領域，各家技術都有其優勢。&lt;/p>
&lt;ul>
&lt;li>OpenAI 提供的嵌入向量有 3,072 維，而&lt;/li>
&lt;li>Google 提供的嵌入向量則有 1,000 多維。Google 利用了其搜尋引擎的算法來生成這些嵌入向量。&lt;/li>
&lt;/ul>
&lt;p>不過市面上有很多開源的 embedding model ，距離的算法也很多，用的場景也不一樣&lt;/p>
&lt;h3 id="即時更新最新的資料">即時更新最新的資料 &lt;a href="#%e5%8d%b3%e6%99%82%e6%9b%b4%e6%96%b0%e6%9c%80%e6%96%b0%e7%9a%84%e8%b3%87%e6%96%99" class="anchor">🔗&lt;/a>&lt;/h3>&lt;ul>
&lt;li>假設你是一個電商 你就可以透過 Embedding 在不把資料庫暴露的情況 update 最新資料, 你這時候就會有疑問 fine-tune 呢？？ 主要是貴 fine-tune 適用在模型更新不頻繁的時候&lt;/li>
&lt;/ul>
&lt;h2 id="fine-tune">Fine-tune &lt;a href="#fine-tune" class="anchor">🔗&lt;/a>&lt;/h2>&lt;p>Fine-tune 是在模型更新不頻繁時的最佳選擇，雖然成本較高，但能針對特定需求進行調整。Fine-tune 可以看作是對 LLM 的進一步教育，讓它在既有的基礎上更好地適應特定任務。&lt;/p></description></item></channel></rss>