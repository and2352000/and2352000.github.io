<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI on Aaron's Blog</title><link>https://and2352000.github.io/tags/ai/</link><description>Recent content in AI on Aaron's Blog</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 17 Jun 2024 14:09:20 +0800</lastBuildDate><atom:link href="https://and2352000.github.io/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Google Cloud Submit Review</title><link>https://and2352000.github.io/posts/8-google-cloud-submit-review/</link><pubDate>Mon, 17 Jun 2024 14:09:20 +0800</pubDate><guid>https://and2352000.github.io/posts/8-google-cloud-submit-review/</guid><description>這次的 Google Cloud Submit 可以用 AI 來總結 🔗副標題可以叫做 RAG(Retrieval-Augmented Generation) 🔗這次的議程我參加了兩個 Workshop
Migration from PostgreSQL to Alloy DB for accelerating GenAl Vector Search &amp;amp; Embedding Multimodality with Gemini 有趣的案例 🔗語音客製化
Vertex AI 能夠進行類似人類的對話和互動，使得與客戶的交流更加自然，根據不同的語調性別年齡產生不同的語音還回應。 輿情分析 Tag 系統
輿情分析的時候需要大量的人原來對留言進行標注，這時候LLM 就很適合代替標注的人員 LLM 的誤解 🔗大多數人已經對 LLM 有所涉獵，但對其局限性認識不足。LLM 雖然功能強大，但在相似度搜索方面還不夠精確，而且有時候會唬爛。因此，需要使用 RAG 來提高搜索的精確性， 通常來講你必須給他一個比較既定事實陳述
Embedding 的基本概念 🔗簡單來說，Embedding 就是將一個對象轉換成向量，對象可以是任何數據（如語音、影片、文字）。然後透過向量搜索引擎找到與之最近的對象（即相似度最高的對象）。距離的算法有很多種，適用的場景也各不相同，有些適合全文搜索，有些則適合其他用途。
在 Embedding 領域，各家技術都有其優勢。
OpenAI 提供的嵌入向量有 3,072 維，而 Google 提供的嵌入向量則有 1,000 多維。Google 利用了其搜尋引擎的算法來生成這些嵌入向量。 不過市面上有很多開源的 embedding model ，距離的算法也很多，用的場景也不一樣
即時更新最新的資料 🔗 假設你是一個電商 你就可以透過 Embedding 在不把資料庫暴露的情況 update 最新資料, 你這時候就會有疑問 fine-tune 呢？？ 主要是貴 fine-tune 適用在模型更新不頻繁的時候 Fine-tune 🔗Fine-tune 是在模型更新不頻繁時的最佳選擇，雖然成本較高，但能針對特定需求進行調整。Fine-tune 可以看作是對 LLM 的進一步教育，讓它在既有的基礎上更好地適應特定任務。</description></item></channel></rss>